# rpc
rpc by go

[gRPC原理学习概述](./gRPC学习.md)

### 简介：
RPC 的全称是 Remote Procedure Call，即远程过程调用

具有以下作用：
1. 屏蔽远程调用跟本地调用的区别，让我们感觉就是调用项目内的方法；
2. 隐藏底层网络通信的复杂性，让我们更专注于业务逻辑。

### RPC通信流程：
步骤如下：

1. RPC是远程调用，需要网络传输数据，并且由于常用于业务系统之间进行远程调用，所以需要使用TCP来进行传输

2. 网络传输的数据必须是二进制数据，但是调用方请求的出入参数都是对象，所以需要使用可逆的算法，来将对象转化为二进制数据，这一步叫做序列化

3. 调用方持续的将请求序列化为二进制数据，经过TCP后传输给了服务提供方。服务提供方如何知道请求的数据的大小，以及请求的是哪个接口类型；因此需要约定数据包的格式，这个步骤就是协议的约定

4. 根据协议格式，服务提供者可以正确的从二进制数据中分割出不同的请求，同事根据请求类型和序列化类型，把二进制的消息体逆向还原成请求对象，这一步就叫反序列化

5. 服务提供方根据反序列化出来的请求对象，找到对象的实现类，完成方法调用

6. 将执行结果序列化后，回写到TCP通道中。调用方获取到应答数据后，再进行反序列化得到Reponse数据，完成RPC调用

7. 简化调用链，利用反射或者其他方法让调用方在调用远程方法时，能够像调用本地接口一样

    ![image-20210522164901880](https://gitee.com/Euraxluo/images/raw/master/picgo/image-20210522164901880.png)


### RPC 注意点

1. 使用rpc的场景是否合适，
2. 什么是否需要开启压缩，根据配置，根据部署机器配置，根据网络环境，根据传输数据大小
3. 调用过程超时处理，以及失败重试机制，例如dubbo的failfast，failover等
4. 服务集群注意点
    1. 服务注册，发现，服务注册中心
    2. 服务治理，服务分组，服务别名，服务限流，服务降级，服务调用链，链路跟踪
    3. 服务监控，调用链监控，方法监控，数据指标监控（TPS，调用量，可用率，调用返回时间，服务网络响应时间）
    4. 服务日志，聚合查询，整理，告警
    5. 服务集群化，分组化的在线配置中心。支持日志等级控制，服务控制

### RPC协议

**RPC协议简介**

- RPC请求在发送到网络中之前，需要将请求转为二进制数据，基于TCP连接和服务方通信，TCP链接会根据系统配置和TCP窗口大小，在同一个TCP链接中，对数据包进行拆分，合并。服务方需要正确处理TCP通道中的二进制数据。

- RPC协议是一种应用层协议，主要负责应用间的通信，相对于HTTP协议，需要的性能更高，并且RPC是有状态的协议，请求和响应一一对应。RPC一般会设计更加紧凑的私有协议

**RPC协议的设计**

- 消息边界语义：利用一个定长数据来保存整个请求协议体的大小；先读取固定长度的位置里面的值，得到协议体长度，再去读取整个协议体的数据

    ![image-20210522162421147](https://gitee.com/Euraxluo/images/raw/master/picgo/image-20210522162421147.png)

- 协议数据序列化方法信息：利用定长的位置存储协议数据的序列化方式

- 将整个协议分为协议头和协议体，得到定长协议头，该协议头是不可扩展的

    ![image-20210522162430292](https://gitee.com/Euraxluo/images/raw/master/picgo/image-20210522162430292.png)

- 可扩展协议，将协议头改为可扩展的。将协议分为三部分：固定部分，协议头内容，协议体内容；前两部分统称为协议头

    ![image-20210522162827231](https://gitee.com/Euraxluo/images/raw/master/picgo/image-20210522162827231.png)

- RPC为了吞吐量，都是异步并发发送的请求，等待服务应答，因此需要消息ID，来判断应答对应哪个请求




**golang 实现rpc序列化**

RPC客户端调用如下:
`err = client.Call("service.Method",args,&reply)`
客户端发送的请求有包含服务名,方法名,参数列表
服务端返回的响应有错误,返回值
将请求和响应中的参数和返回值抽象为body,那么剩余的信息可以抽象为一个Header

```go
type Header struct {
	ServiceMethod string //服务名和方法名
	Seq uint64 //请求序号
	Error string //客户端为空,服务端如果发生错误,会把错误信息放到Error中
}
```

### 网络通信

**常见的网络IO模型**

- 同步阻塞 IO（BIO）
    - 在 Linux 中，默认情况下所有的 socket 都是 blocking 的
    - 应用进程发起 IO 系统调用后，应用进程被阻塞，转到内核空间处理。之后，内核开始等待数据，等待到数据之后，再将内核中的数据拷贝到用户内存中，整个 IO 处理完毕后返回进程。最后应用的进程解除阻塞状态，运行业务逻辑。
    - ![image-20210522185621450](https://gitee.com/Euraxluo/images/raw/master/picgo/image-20210522185621450.png)
    - 系统内核处理 IO 操作分为两个阶段——等待数据和拷贝数据。而在这两个阶段中，应用进程中 IO 操作的线程会一直都处于阻塞状态，如果是基于 Java 多线程开发，那么每一个 IO 操作都要占用线程，直至 IO 操作结束。
    - 阻塞 IO 每处理一个 socket 的 IO 请求都会阻塞进程（线程），但使用难度较低。在并发量较低、业务逻辑只需要同步进行 IO 操作的场景下，阻塞 IO 已经满足了需求，并且不需要发起 select 调用，开销上还要比 IO 多路复用低。
- 同步非阻塞 IO（NIO）
- 同步IO 多路复用（select，poll，epoll）
    - 多路复用 IO 是在高并发场景中使用最为广泛的一种 IO 模型
    - linux总的多个网络连接的 IO 可以注册到一个复用器（select）上，当用户进程调用了 select，那么整个进程会被阻塞。同时，内核会“监视”所有 select 负责的 socket，当任何一个 socket 中的数据准备好了，select 就会返回。这个时候用户进程再调用 read 操作，将数据从内核中拷贝到用户进程。
    - 优势在于，用户可以在一个线程内同时处理多个 socket 的 IO 请求。用户可以注册多个 socket，然后不断地调用 select 读取被激活的 socket，即可达到在同一个线程内同时处理多个 IO 请求的目的。而在同步阻塞模型中，必须通过多线程的方式才能达到这个目的。
    - IO 多路复用更适合高并发的场景，可以用较少的进程（线程）处理较多的 socket 的 IO 请求。
- 异步非阻塞 IO（AIO）

**RPC网络io模型**

RPC 调用在大多数的情况下，是一个高并发调用的场景

- 在 RPC 框架的实现中，在网络通信的处理上，我们会选择 IO 多路复用的方式。

- 选择基于 Reactor 模式实现的io框架来实现IO多路复用

- 在 Linux 环境下，也要开启 epoll 来提升系统性能（Windows 环境下是无法开启 epoll 的，因为系统内核不支持）。

**网络io中的零拷贝**

系统内核处理 IO 操作分为两个阶段——等待数据和拷贝数据。

- 等待数据，就是系统内核在等待网卡接收到数据后，把数据写到内核中
- 拷贝数据，就是系统内核在获取到数据后，将数据拷贝到用户进程的空间中。

应用进程的每一次写操作，都会把数据写到用户空间的缓冲区中，再由 CPU 将数据拷贝到系统内核的缓冲区中，之后再由 DMA 将这份数据拷贝到网卡中，最后由网卡发送出去。一次写操作数据要拷贝两次才能通过网卡发送出去

![image-20210522192234064](https://gitee.com/Euraxluo/images/raw/master/picgo/image-20210522192234064.png)

- 零拷贝技术
    - 零拷贝，就是取消用户空间与内核空间之间的数据拷贝操作，应用进程每一次的读写操作，都可以通过一种方式，让应用进程向用户空间写入或者读取数据，就如同直接向内核空间写入或者读取数据一样，再通过 DMA 将内核中的数据拷贝到网卡，或将网卡中的数据 copy 到内核。
- 零拷贝实现
    - mmap+write 方式，核心原理是通过虚拟内存来解决的
    - sendfile 方式
- Netty零拷贝实现：
    - 用户空间数据操作零拷贝优化
        - 收到数据包后，在对数据包进行处理时，需要根据协议，处理数据包，在进行处理时，免不了需要进行在用户空间内部内存中进行拷贝处理，Netty就是在用户空间中对数据操作进行优化
        - Netty 提供了 CompositeByteBuf 类，它可以将多个 ByteBuf 合并为一个逻辑上的  ByteBuf，避免了各个 ByteBuf 之间的拷贝。
        - ByteBuf 支持 slice 操作，因此可以将 ByteBuf 分解为多个共享同一个存储区域的 ByteBuf，避免了内存的拷贝。
        - 通过 wrap 操作，我们可以将 byte[] 数组、ByteBuf、ByteBuffer  等包装成一个 Netty ByteBuf 对象, 进而避免拷贝操作。
    - 用户空间与内核空间之间零拷贝优化
        - Netty  的  ByteBuffer 可以采用 Direct Buffers，使用堆外直接内存进行 Socket 的读写操作，效果和虚拟内存所实现的效果是一样的。
        - Netty  还提供  FileRegion  中包装  NIO  的  FileChannel.transferTo()  方法实现了零拷贝，这与 Linux  中的  sendfile  方式在原理上也是一样的。

### 屏蔽RPC处理流程

- java使用动态代理屏蔽实现细节
- golang使用反射等，来实现的



## 实现篇





客户端与服务端通信需要协商内容,对于rpc来说,会在报文的最开始使用固定的直接协商信息,包括序列化方式,压缩方式,header长度,body长度等
对于我们的rpc来说,目前需要协商的内容是编解码方式.我们可以使用选项模式,来应对以后的变化

```go
const MagicNumber = 0x3bef5c
type Option struct {
	MagicNumber int //魔数,标识服务端的系统
	CodecType codec.Type
}

var DefaultOption = &Option{
	MagicNumber:MagicNumber,
	CodecType:codec.GobType,
}
```

我们的客户端为了便于实现,
固定采用 JSON 编码 Option，后续的 header 和 body 的编码方式由 Option 中的 CodeType 指定，
服务端首先使用 JSON 解码 Option，然后通过 Option 中指定的 CodeType 解码剩余的内容。即报文将以这样的形式发送
| Option{MagicNumber: xxx, CodecType: xxx} | Header{ServiceMethod ...} | Body interface{} |
| <------      固定 JSON 编码      ------>  | <-------   编码方式由 CodeType 决定   ------->|

### 